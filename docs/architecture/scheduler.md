# ğŸ• Scheduler pentru Scraping Automat

## ğŸ“‹ Overview

Sistem flexibil de scheduling pentru scraping automat al actelor legislative de pe legislatie.just.ro, cu:
- **3 tipuri de schedule**: Daily (Luni-Joi), Weekly, Custom
- **Auto-import** Ã®n baza de date
- **Management facil** prin PowerShell scripts
- **Docker support** pentru deployment

## ğŸš€ Quick Start

### Windows (PowerShell)

```powershell
# Install dependencies
pip install -r requirements-scheduler.txt

# Start scheduler (Luni-Joi la 14:00)
.\manage-scheduler.ps1 start

# Test imediat
.\manage-scheduler.ps1 test -Now

# Vezi status
.\manage-scheduler.ps1 status

# Vezi logs
.\manage-scheduler.ps1 logs
```

### Linux/Docker

```bash
# Build È™i start cu Docker Compose
docker-compose -f docker-compose.scheduler.yml up -d

# Vezi logs
docker-compose -f docker-compose.scheduler.yml logs -f scheduler

# Stop
docker-compose -f docker-compose.scheduler.yml down
```

## âš™ï¸ Configurare

### OpÈ›iuni de Schedule

#### 1. **Daily Weekdays** (Recomandat)
RuleazÄƒ la aceeaÈ™i orÄƒ, Luni-Joi (sau alte zile):

```env
SCRAPER_SCHEDULE_TYPE=daily_weekdays
SCRAPER_HOUR=14              # 14:00 (2 PM)
SCRAPER_DAYS=1-4             # Luni-Joi
```

**Exemple de zile:**
- `1-4` = Luni pÃ¢nÄƒ Joi
- `1-5` = Luni pÃ¢nÄƒ Vineri
- `1,3,5` = Luni, Miercuri, Vineri
- `2,4` = MarÈ›i, Joi

#### 2. **Weekly** (O datÄƒ pe sÄƒptÄƒmÃ¢nÄƒ)
RuleazÄƒ o singurÄƒ datÄƒ pe sÄƒptÄƒmÃ¢nÄƒ:

```env
SCRAPER_SCHEDULE_TYPE=weekly
SCRAPER_WEEKLY_DAY=1         # 1=Luni, 2=MarÈ›i, ..., 7=DuminicÄƒ
SCRAPER_WEEKLY_HOUR=10       # 10:00 (10 AM)
```

#### 3. **Custom** (Expresie Cron avansatÄƒ)
Control total prin cron expression:

```env
SCRAPER_SCHEDULE_TYPE=custom
SCRAPER_CRON_EXPRESSION="0 14 * * 1-4"
```

**Exemple de expresii cron:**
```
"0 14 * * 1-4"        # 14:00 Luni-Joi
"0 10 * * 1"          # 10:00 Ã®n fiecare Luni
"0 8,14,20 * * *"     # 8 AM, 2 PM, 8 PM zilnic
"0 */6 * * *"         # La fiecare 6 ore
"30 9 * * 1-5"        # 9:30 AM Luni-Vineri
"0 0 * * 0"           # Miezul nopÈ›ii Ã®n fiecare DuminicÄƒ
```

**Format Cron:** `minute hour day_of_month month day_of_week`
- minute: 0-59
- hour: 0-23
- day_of_month: 1-31
- month: 1-12
- day_of_week: 0-7 (0 È™i 7 = DuminicÄƒ, 1=Luni, ..., 6=SÃ¢mbÄƒtÄƒ)

### Configurare CompletÄƒ (.env.scheduler)

```env
# Enable/disable
SCRAPER_ENABLED=true

# Schedule
SCRAPER_SCHEDULE_TYPE=daily_weekdays
SCRAPER_HOUR=14
SCRAPER_DAYS=1-4

# Scraper settings
SCRAPER_DELAY=2.0                           # Delay Ã®ntre requests (secunde)
SCRAPER_LINKS_FILE=linkuri_legislatie.txt   # FiÈ™ier cu linkuri
SCRAPER_OUTPUT_DIR=rezultate                # Director output

# Auto-import Ã®n DB
SCRAPER_AUTO_IMPORT=true
SCRAPER_API_URL=http://localhost:8000

# AI Processing (NEW)
AI_PROCESSING_ENABLED=true
AI_PROCESSING_SCHEDULE=*/30 * * * *   # Every 30 minutes
AI_PROCESSING_BATCH_SIZE=10           # Articles per batch
AI_PROCESSING_DELAY=1.0               # Delay between API calls

# Export to Issue Monitoring (NEW)
EXPORT_ENABLED=true
EXPORT_SCHEDULE=0 * * * *             # Every hour
EXPORT_BATCH_SIZE=10                  # Acts per batch
EXPORT_SYNC_ENABLED=true              # Enable incremental sync
EXPORT_SYNC_SCHEDULE=30 * * * *       # Every hour at :30
```

## ğŸ¤– AI Processing & Export (NEW)

### Workflow Complet

```
1. Scraper (Luni-Joi 14:00)
   â†“ Extrage legislaÈ›ie
   â†“ SalveazÄƒ Ã®n DB
   
2. AI Processing (Every 30 min)
   â†“ ProceseazÄƒ articole pending
   â†“ Extrage issues/probleme
   â†“ GenereazÄƒ metadate
   
3. Export (Every hour)
   â†“ Trimite la Issue Monitoring
   â†“ MarcheazÄƒ ca exportat
   
4. Export Sync (Every hour at :30)
   â†“ SincronizeazÄƒ updates
   â†“ Trimite articole/anexe noi
```

### Configurare AI

```env
# In db_service/.env
OPENAI_API_KEY=sk-proj-xxxxx
ANTHROPIC_API_KEY=sk-ant-xxxxx
AI_PROVIDER=openai
AI_MODEL=gpt-4o

ISSUE_MONITORING_API_URL=https://api.issuemonitoring.ro/v1
ISSUE_MONITORING_API_KEY=your_key_here
```

### Schedule-uri Recomandate

**Development/Testing:**
```env
AI_PROCESSING_SCHEDULE=*/5 * * * *    # Every 5 minutes
EXPORT_SCHEDULE=*/10 * * * *          # Every 10 minutes
```

**Production:**
```env
AI_PROCESSING_SCHEDULE=*/30 * * * *   # Every 30 minutes
EXPORT_SCHEDULE=0 * * * *             # Every hour (on the hour)
EXPORT_SYNC_SCHEDULE=30 * * * *       # Every hour (at :30)
```

**Low Volume:**
```env
AI_PROCESSING_SCHEDULE=0 */2 * * *    # Every 2 hours
EXPORT_SCHEDULE=0 */4 * * *           # Every 4 hours
```

## ğŸ“– Utilizare

### Command Line Interface

```bash
# Start scheduler
python scheduler.py

# Run imediat (test)
python scheduler.py --now

# Show config
python scheduler.py --show-config

# Test cron expression
python scheduler.py --test-cron "0 14 * * 1-4"
```

### PowerShell Management Script

```powershell
# Start cu setÄƒri default (Luni-Joi 14:00)
.\manage-scheduler.ps1 start

# Start cu setÄƒri custom
.\manage-scheduler.ps1 start -Schedule daily_weekdays -Hour 10 -Days "1-5"

# Stop scheduler
.\manage-scheduler.ps1 stop

# Restart
.\manage-scheduler.ps1 restart

# Status
.\manage-scheduler.ps1 status

# View logs (follow mode)
.\manage-scheduler.ps1 logs

# Test imediat
.\manage-scheduler.ps1 test -Now

# Show config
.\manage-scheduler.ps1 config

# Storage stats (NEW)
.\manage-scheduler.ps1 stats

# Cleanup old files (NEW)
.\manage-scheduler.ps1 cleanup
```

## ğŸ§¹ File Cleanup Management

### Auto-Cleanup

Scheduler-ul poate È™terge automat fiÈ™ierele duplicate dupÄƒ import.

**Configurare Ã®n `.env.scheduler`:**
```env
SCRAPER_AUTO_CLEANUP=true  # Enable auto-cleanup
```

**Comportament:**
- RuleazÄƒ dupÄƒ fiecare import cu succes
- PÄƒstreazÄƒ doar **cel mai recent fiÈ™ier** per act
- È˜terge toate duplicate mai vechi (CSV + MD)
- MenÈ›ine folder-ul `rezultate/` mic constant

**Exemplu log:**
```
2025-11-08 14:05:40 - INFO - âœ… Import completed: 7 acts
2025-11-08 14:05:41 - INFO - ğŸ§¹ Running auto-cleanup...
2025-11-08 14:05:42 - INFO - âœ… Deleted 14 files
```

### Manual Cleanup

**PowerShell:**
```powershell
# Vezi statistici storage
.\manage-scheduler.ps1 stats

# Cleanup manual
.\manage-scheduler.ps1 cleanup
```

**Python direct:**
```bash
# Vezi statistici (safe, nu modificÄƒ nimic)
python cleanup_files.py --stats

# Preview cleanup (dry run - aratÄƒ ce ar È™terge)
python cleanup_files.py

# ExecutÄƒ cleanup efectiv
python cleanup_files.py --execute

# Quiet mode (doar rezultat final)
python cleanup_files.py --execute --quiet
```

### Cleanup Output

**Preview (dry-run):**
```
ğŸ“Š Found 7 acts with duplicates

ğŸ“„ LEGE_121_2024
   âœ… KEEP:   LEGE_121_2024_20251108_000715.csv (2025-11-08 00:07:15)
   âŒ DELETE: LEGE_121_2024_20251107_211711.csv (0 days old)

ğŸ” DRY RUN: Would delete 14 files
   Run with --execute to actually delete
```

**Statistici:**
```
ğŸ“Š Storage Statistics
Total files:    7 CSV + 7 MD = 14
Total size:     1.87 MB
Average size:   136.51 KB per file

âœ… No duplicates found - optimal storage
```

### Storage Strategy

| Layer | Retention | Purpose |
|-------|-----------|---------|
| **rezultate/** | Latest only | Temporary staging, auto-cleanup |
| **PostgreSQL** | Permanent | Source of truth, versioning, diff tracking |
| **Backups** | 30 days | PostgreSQL automated backups |

**Avantaje:**
- âœ… Storage mic constant (~2 MB pentru 7 acte)
- âœ… No manual intervention needed
- âœ… Recovery din PostgreSQL database
- âœ… Export API disponibil on-demand

### Docker Deployment

```bash
# Start scheduler service
docker-compose -f docker-compose.scheduler.yml up -d

# View logs
docker-compose -f docker-compose.scheduler.yml logs -f

# Stop
docker-compose -f docker-compose.scheduler.yml down

# Rebuild
docker-compose -f docker-compose.scheduler.yml up -d --build
```

## ğŸ“Š Monitoring & Logs

### Log Files

**scraper_scheduler.log** - Log principal cu toate evenimente:
```
2025-11-07 14:00:00 - INFO - ğŸš€ Starting scheduled scraping job
2025-11-07 14:00:05 - INFO - ğŸ“¥ Running scraper...
2025-11-07 14:05:30 - INFO - âœ… Scraping completed in 330.45 seconds
2025-11-07 14:05:35 - INFO - ğŸ“¤ Auto-importing to database...
2025-11-07 14:05:40 - INFO - âœ… Import result: {'success': True, 'updated_acts': 3}
2025-11-07 14:05:40 - INFO - ğŸ Scheduled job completed
```

### Status Check

```powershell
# Windows
.\manage-scheduler.ps1 status

# Output:
# Status: RUNNING
# Processes:
#   PID: 12345
#   Memory: 45.6 MB
#   Start Time: 2025-11-07 13:00:00
# 
# Last 5 log entries:
# ...
```

### Next Run Time

```bash
python scheduler.py --show-config

# Output includes:
# â° Next 5 scheduled runs:
#    1. 2025-11-11 14:00:00 Monday
#    2. 2025-11-12 14:00:00 Tuesday
#    3. 2025-11-13 14:00:00 Wednesday
#    4. 2025-11-14 14:00:00 Thursday
#    5. 2025-11-18 14:00:00 Monday
```

## ğŸ”§ ConfigurÄƒri Avansate

### Misfire Grace Time

DacÄƒ un job nu poate rula la timpul programat (ex: sistem oprit), poate rula Ã®n urmÄƒtoarele 60 minute:

```python
# Ãn scheduler.py
misfire_grace_time=3600  # 1 hour
```

### Coalesce Multiple Runs

DacÄƒ mai multe run-uri au fost missed, le combinÄƒ Ã®ntr-unul singur:

```python
coalesce=True
```

### Max Instances

Permite doar o instanÈ›Äƒ a job-ului sÄƒ ruleze simultan:

```python
max_instances=1
```

### Custom Delay

AjusteazÄƒ delay-ul Ã®ntre requests pentru a fi respectuos cu serverul:

```env
SCRAPER_DELAY=3.0  # 3 secunde Ã®ntre requests
```

## ğŸ› Troubleshooting

### Scheduler nu porneÈ™te

1. **VerificÄƒ dependinÈ›ele:**
   ```bash
   pip install -r requirements-scheduler.txt
   ```

2. **VerificÄƒ fiÈ™ierul de linkuri:**
   ```bash
   # Trebuie sÄƒ existe linkuri_legislatie.txt
   ls linkuri_legislatie.txt
   ```

3. **VerificÄƒ permisiunile:**
   ```bash
   # Windows: ruleazÄƒ PowerShell ca Administrator
   # Linux: verificÄƒ permisiuni execute
   chmod +x scheduler.py
   ```

### Auto-import eÈ™ueazÄƒ

1. **VerificÄƒ cÄƒ API-ul ruleazÄƒ:**
   ```bash
   curl http://localhost:8000/health
   ```

2. **VerificÄƒ URL-ul API:**
   ```env
   SCRAPER_API_URL=http://localhost:8000  # Correct
   # NOT: http://localhost:8000/api/v1
   ```

3. **VerificÄƒ network (Docker):**
   ```bash
   docker network ls
   # AsigurÄƒ-te cÄƒ scheduler È™i API sunt Ã®n aceeaÈ™i reÈ›ea
   ```

### Job nu ruleazÄƒ la timp

1. **VerificÄƒ expresia cron:**
   ```bash
   python scheduler.py --test-cron "0 14 * * 1-4"
   ```

2. **VerificÄƒ timezone:**
   ```python
   # Scheduler foloseÈ™te timezone-ul local al sistemului
   # VerificÄƒ cu: python -c "import datetime; print(datetime.datetime.now())"
   ```

3. **VerificÄƒ logs pentru errors:**
   ```bash
   tail -f scraper_scheduler.log
   ```

## ğŸ“… Exemple de ConfigurÄƒri

### Scenario 1: Actualizare zilnicÄƒ Luni-Joi

```env
# RuleazÄƒ Ã®n fiecare zi lucrÄƒtoare (Luni-Joi) la ora 14:00
SCRAPER_SCHEDULE_TYPE=daily_weekdays
SCRAPER_HOUR=14
SCRAPER_DAYS=1-4
```

### Scenario 2: Actualizare sÄƒptÄƒmÃ¢nalÄƒ

```env
# RuleazÄƒ doar Luni dimineaÈ›a la 10:00
SCRAPER_SCHEDULE_TYPE=weekly
SCRAPER_WEEKLY_DAY=1
SCRAPER_WEEKLY_HOUR=10
```

### Scenario 3: ActualizÄƒri frecvente (test/development)

```env
# RuleazÄƒ la fiecare 4 ore
SCRAPER_SCHEDULE_TYPE=custom
SCRAPER_CRON_EXPRESSION="0 */4 * * *"
```

### Scenario 4: Actualizare la final de sÄƒptÄƒmÃ¢nÄƒ

```env
# RuleazÄƒ Vineri seara la 18:00
SCRAPER_SCHEDULE_TYPE=weekly
SCRAPER_WEEKLY_DAY=5
SCRAPER_WEEKLY_HOUR=18
```

### Scenario 5: Multiple run-uri pe zi

```env
# RuleazÄƒ la 8 AM, 2 PM È™i 8 PM, Luni-Vineri
SCRAPER_SCHEDULE_TYPE=custom
SCRAPER_CRON_EXPRESSION="0 8,14,20 * * 1-5"
```

## ğŸ” Production Best Practices

### 1. Logging

ConfigureazÄƒ log rotation:
```bash
# Linux: foloseÈ™te logrotate
# /etc/logrotate.d/scraper-scheduler
/path/to/scraper_scheduler.log {
    daily
    rotate 7
    compress
    missingok
    notifempty
}
```

### 2. Monitoring

Setup alerting pentru job failures:
```python
# AdaugÄƒ Ã®n scheduler.py
def send_alert(message):
    # Email, Slack, etc.
    pass

def _job_executed_listener(self, event):
    if event.exception:
        send_alert(f"Scraper failed: {event.exception}")
```

### 3. Resource Limits

SeteazÄƒ limite Ã®n Docker:
```yaml
# docker-compose.scheduler.yml
services:
  scheduler:
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 512M
```

### 4. Health Checks

MonitorizeazÄƒ prin health endpoint:
```bash
# Check dacÄƒ scheduler ruleazÄƒ
docker ps | grep legislatie_scheduler
docker inspect legislatie_scheduler --format='{{.State.Health.Status}}'
```

## ğŸ“š ReferinÈ›e

- **APScheduler Documentation**: https://apscheduler.readthedocs.io/
- **Cron Expression Guide**: https://crontab.guru/
- **Python datetime**: https://docs.python.org/3/library/datetime.html

## ğŸ¤ Support

Pentru probleme sau Ã®ntrebÄƒri:
1. VerificÄƒ `scraper_scheduler.log`
2. RuleazÄƒ `python scheduler.py --show-config`
3. TesteazÄƒ manual cu `python scheduler.py --now`

---

**Versiune:** 1.0  
**Data:** 2025-11-07  
**Status:** âœ… Production Ready
