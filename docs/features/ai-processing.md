# ğŸ¤– AI Processing & Export Strategy

## ArhitecturÄƒ CompletÄƒ

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      PARSER-LAW                            â”‚
â”‚                 (Orchestrator Complet)                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚   SCRAPING   â”‚ â†’ â”‚ AI PROCESSINGâ”‚ â†’ â”‚   EXPORT   â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚         â†“                   â†“                    â†“        â”‚
â”‚  LegislaÈ›ie brutÄƒ    Issues+Metadate    CÄƒtre Issue     â”‚
â”‚                                           Monitoring      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ”„ Workflow Complet

### **Faza 1: Scraping & Detectare NoutÄƒÈ›i**
```python
# scraper_legislatie.py
1. Scraping legislatie.gov.ro
2. Parsare HTML â†’ Acte + Articole + Anexe
3. Detectare noutÄƒÈ›i:
   - Acte complet noi
   - Articole noi Ã®n acte existente
   - ModificÄƒri articole existente
4. Stocare Ã®n BD cu status:
   - ai_status = 'pending'
   - export_status = 'pending'
```

### **Faza 2: Procesare AI**
```python
# Nou serviciu: ai_processor.py
1. SELECT * FROM v_pending_ai_processing LIMIT 10
2. Pentru fiecare element (act/articol/anexÄƒ):
   
   a) Trimitere la AI (OpenAI/Claude):
      - Prompt: "Extrage issues din acest text legislativ"
      - Prompt: "GenereazÄƒ sumarizare/metadate"
   
   b) Primire rÄƒspuns AI:
      - issues: [{"denumire": "...", "descriere": "...", "confidence": 0.95}]
      - metadate: "Sumarizare text..."
   
   c) Stocare Ã®n BD:
      - INSERT INTO issues (denumire, descriere, source='ai', confidence_score)
      - INSERT INTO articole_issues (articol_id, issue_id, adaugat_de='ai')
      - UPDATE articole SET metadate='...', ai_status='completed'
   
   d) Logging & Error Handling:
      - DacÄƒ AI fail â†’ ai_status='error', ai_error='...'
```

### **Faza 3: Export cÄƒtre Issue Monitoring**
```python
# Nou serviciu: export_service.py
1. SELECT * FROM v_pending_export LIMIT 5
2. Pentru fiecare act complet:
   
   a) Construire pachet complet:
      {
        "act": {...},
        "articole": [
          {
            "id": 1,
            "text": "...",
            "metadate": "...",
            "issues": [{"denumire": "...", "descriere": "..."}]
          }
        ],
        "anexe": [...],
        "act_issues": [...]
      }
   
   b) POST https://issue-monitoring.ro/api/import/legislation
      Headers: {"Authorization": "Bearer TOKEN"}
      Body: JSON complet
   
   c) Primire rÄƒspuns:
      {
        "success": true,
        "act_id": 12345,  # ID Ã®n BD Issue Monitoring
        "articole_ids": [67, 68, 69],
        "issues_ids": [101, 102]
      }
   
   d) Update local:
      - UPDATE acte_legislative SET 
          export_status='exported',
          issue_monitoring_id=12345,
          export_at=NOW()
      - UPDATE articole SET issue_monitoring_id=... WHERE id IN (...)
      - UPDATE issues SET issue_monitoring_id=... WHERE id IN (...)
```

---

## ğŸ“Š Schema BazÄƒ de Date

### **Tabele Principale**
```sql
-- Acte cu tracking AI & Export
acte_legislative:
  - ai_status: pending â†’ processing â†’ completed/error
  - ai_processed_at, ai_error
  - metadate: TEXT (sumarizare generatÄƒ de AI)
  - export_status: pending â†’ exported/error
  - export_at, export_error
  - issue_monitoring_id: INTEGER (ID Ã®n BD Issue Monitoring)

-- Articole cu tracking AI
articole:
  - ai_status, ai_processed_at, ai_error
  - metadate: TEXT (explicaÈ›ie generatÄƒ de AI)
  - issue_monitoring_id: INTEGER

-- Issues extrase de AI
issues:
  - denumire, descriere
  - source: 'ai' | 'manual'
  - confidence_score: DECIMAL(3,2)  # 0.95 = 95% confidence
  - issue_monitoring_id: INTEGER

-- Anexe cu tracking AI
anexe:
  - continut, metadate
  - ai_status, ai_processed_at, ai_error
  - issue_monitoring_id: INTEGER

-- RelaÈ›ii many-to-many
articole_issues, acte_issues, anexe_issues:
  - adaugat_de: 'ai' | 'manual'
```

### **Views pentru Monitorizare**
```sql
-- Elemente care aÈ™teaptÄƒ AI
v_pending_ai_processing:
  - tip (act/articol/anexÄƒ)
  - identificator
  - ai_status, ai_error

-- Acte gata de export
v_pending_export:
  - act_id, tip_act, numar
  - nr_articole, nr_anexe, nr_issues
  - ai_status='completed', export_status='pending'

-- Pachet complet pentru export
v_export_package:
  - act complet
  - articole cu metadate È™i issues (JSON)
  - anexe cu metadate È™i issues (JSON)
  - issues la nivel de act (JSON)
```

---

## ğŸš€ Implementare Pas cu Pas

### **Pasul 1: Migrare BD** âœ…
```bash
# RuleazÄƒ pe producÈ›ie
psql -h localhost -U legislatie_user -d legislatie_db \
  -f db_service/migrations/add_ai_processing.sql
```

### **Pasul 2: Serviciu AI Processing**
```python
# db_service/app/services/ai_service.py
class AIService:
    async def process_pending_items(self, limit=10):
        """ProceseazÄƒ elemente pending cu AI"""
        
    async def extract_issues(self, text: str) -> List[Issue]:
        """Extrage issues din text cu OpenAI/Claude"""
        
    async def generate_metadata(self, text: str) -> str:
        """GenereazÄƒ sumarizare/metadate"""
```

### **Pasul 3: Serviciu Export**
```python
# db_service/app/services/export_service.py
class ExportService:
    async def export_to_issue_monitoring(self, act_id: int):
        """ExportÄƒ act complet cÄƒtre Issue Monitoring"""
        
    async def build_export_package(self, act_id: int) -> dict:
        """ConstruieÈ™te pachet JSON complet"""
```

### **Pasul 4: Endpoint-uri Noi**
```python
# db_service/app/api/routes/ai_processing.py
POST /api/v1/ai/process          # Trigger procesare AI
GET  /api/v1/ai/status           # Status procesare
POST /api/v1/ai/retry/{id}       # Retry element cu eroare

# db_service/app/api/routes/export.py
POST /api/v1/export/to-im        # Export cÄƒtre Issue Monitoring
GET  /api/v1/export/pending      # Liste acte gata de export
GET  /api/v1/export/status       # Status export
```

### **Pasul 5: Scheduler**
```python
# scheduler.py - adaugÄƒ task-uri noi
@scheduler.scheduled_job('interval', minutes=30)
def process_ai_pending():
    """ProceseazÄƒ automat elemente pending cu AI"""
    
@scheduler.scheduled_job('interval', hours=1)
def export_to_issue_monitoring():
    """ExportÄƒ automat acte procesate cÄƒtre Issue Monitoring"""
```

---

## ğŸ”§ Configurare

### **Environment Variables**
```bash
# .env
# AI Configuration
OPENAI_API_KEY=sk-...
ANTHROPIC_API_KEY=sk-ant-...
AI_PROVIDER=openai  # sau 'anthropic'
AI_MODEL=gpt-4o  # sau 'claude-3-5-sonnet-20241022'
AI_MAX_RETRIES=3
AI_TIMEOUT=60

# Issue Monitoring Integration
ISSUE_MONITORING_API_URL=https://issue-monitoring.ro/api
ISSUE_MONITORING_API_KEY=secret_token_here
EXPORT_BATCH_SIZE=5
```

---

## ğŸ“ˆ Monitorizare & Logging

### **Metrics**
```python
# Tracked Ã®n scheduler
- ai_processing_rate: elemente/orÄƒ
- ai_success_rate: %
- ai_error_rate: %
- export_rate: acte/zi
- export_success_rate: %
```

### **Logging**
```python
# Log structure
{
  "timestamp": "2025-11-08T10:30:00",
  "service": "ai_processor",
  "action": "extract_issues",
  "articol_id": 12345,
  "status": "success",
  "issues_found": 3,
  "confidence_avg": 0.92,
  "processing_time_ms": 1234
}
```

---

## ğŸ¯ Issue Monitoring Integration

### **API Contract**

#### **Endpoint Issue Monitoring:**
```
POST https://issue-monitoring.ro/api/import/legislation
Authorization: Bearer {API_KEY}
Content-Type: application/json

Request Body:
{
  "act": {
    "tip_act": "Legea",
    "numar": "123",
    "data_an": 2025,
    "denumire": "...",
    "metadate": "Sumarizare act..."
  },
  "articole": [
    {
      "articol_nr": "Art. 1",
      "ordine": 1,
      "text_articol": "...",
      "metadate": "ExplicaÈ›ie art. 1...",
      "issues": [
        {
          "denumire": "Taxare electronicÄƒ",
          "descriere": "...",
          "confidence_score": 0.95
        }
      ]
    }
  ],
  "anexe": [...],
  "act_issues": [...]
}

Response:
{
  "success": true,
  "act_id": 12345,
  "articole_mapping": [
    {"parser_law_id": 1, "issue_monitoring_id": 67},
    {"parser_law_id": 2, "issue_monitoring_id": 68}
  ],
  "issues_mapping": [
    {"parser_law_id": 10, "issue_monitoring_id": 101}
  ]
}
```

### **Sincronizare BidirectionalÄƒ**
```python
# Issue Monitoring poate returna modificÄƒri manuale
GET https://issue-monitoring.ro/api/sync/changes?since={timestamp}

Response:
{
  "articole_updates": [
    {
      "issue_monitoring_id": 67,
      "metadate": "Modificare manualÄƒ...",
      "issues": [...]
    }
  ]
}

# Parser-Law aplicÄƒ modificÄƒrile
UPDATE articole 
SET metadate = 'Modificare manualÄƒ...'
WHERE issue_monitoring_id = 67
```

---

## âœ… Checklist Implementare

- [ ] RuleazÄƒ migrare BD (`add_ai_processing.sql`)
- [ ] AdaugÄƒ dependenÈ›e: `openai`, `anthropic` Ã®n `requirements.txt`
- [ ] ImplementeazÄƒ `AIService` cu extractie issues + metadate
- [ ] ImplementeazÄƒ `ExportService` cu construire pachet JSON
- [ ] AdaugÄƒ endpoint-uri `/api/v1/ai/*` È™i `/api/v1/export/*`
- [ ] ConfigureazÄƒ variabile environment (API keys)
- [ ] AdaugÄƒ task-uri Ã®n `scheduler.py`
- [ ] TesteazÄƒ pe date mock
- [ ] Deploy pe producÈ›ie
- [ ] Monitorizare & logging

---

## ğŸ“ Note Tehnice

### **Rate Limiting AI**
```python
# ProtecÈ›ie Ã®mpotriva cost overflow
MAX_TOKENS_PER_REQUEST = 4000
MAX_REQUESTS_PER_MINUTE = 50
COST_THRESHOLD_DAILY = 100.00  # USD
```

### **Retry Strategy**
```python
# Exponential backoff pentru AI errors
RETRY_DELAYS = [5, 30, 300]  # secunde
MAX_RETRIES = 3
```

### **Cache AI Responses**
```python
# EvitÄƒ reprocessare pentru articole identice
# Hash text_articol â†’ Cache metadate/issues 24h
```

---

**UrmÄƒtorul Pas:** Vrei sÄƒ Ã®ncep cu implementarea `AIService` È™i `ExportService`?
