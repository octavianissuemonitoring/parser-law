================================================================================
STRATEGIE IMPLEMENTARE BAZĂ DE DATE POSTGRESQL
Pentru Parser Acte Legislative - Monitorul Oficial
================================================================================

Data: 7 Noiembrie 2025
Versiune: 1.0
Status: Propus - Pregătit pentru Implementare

================================================================================
CONTEXT GENERAL
================================================================================

SISTEMUL COMPLET:
[Parser Acte Legislative] → [PostgreSQL Database] → [LLM Labeling Service] →
[Relevance Analysis] → [Client Assignment] → [Monitoring Platform]

OBIECTIVE:
- Stocare structurată pentru 200-300 acte legislative
- Microserviciu FastAPI pentru acces la date
- Integrare cu serviciul de labeling LLM (ChatGPT/Gemini)
- Suport pentru analiza relevanței și atribuirea clienților
- Monitoring legislativ în timp real

MODIFICĂRI RECENTE:
✅ Terminologie standardizată: denumire → titlu_act, emitent → emitent_act
✅ Cod pregătit pentru integrare cu baza de date
✅ CSV și Markdown cu coloane clare și consistente

================================================================================
DECIZIE 1: ARHITECTURA MICROSERVICIULUI
================================================================================

OPȚIUNI ANALIZATE:
A) REST API Complet (FastAPI standalone)
B) Python Library (import direct)
C) Hibrid (Library + API opțional)

⭐ RECOMANDARE: OPȚIUNEA A - REST API COMPLET (FastAPI)

MOTIVAȚIE:
+ Separare clară a concernurilor
+ Ușor de scalat independent
+ Multiple aplicații pot consuma datele
+ Versionare API (v1, v2)
+ Autentificare/autorizare centralizată
+ Monitoring și logging centralizat

IMPLEMENTARE:
- Framework: FastAPI 0.104+ (async support)
- ORM: SQLAlchemy 2.0+ (modern async style)
- Migrations: Alembic
- Port: 8000 (development), configurable
- Deployment: Docker container

STRUCTURĂ:
db_service/
├── app/
│   ├── __init__.py
│   ├── main.py              # FastAPI app
│   ├── config.py            # Settings
│   ├── database.py          # DB connection
│   ├── models/              # SQLAlchemy models
│   │   ├── __init__.py
│   │   ├── act_legislativ.py
│   │   └── articol.py
│   ├── schemas/             # Pydantic schemas
│   │   ├── __init__.py
│   │   ├── act_schema.py
│   │   └── articol_schema.py
│   ├── api/
│   │   ├── __init__.py
│   │   ├── deps.py          # Dependencies
│   │   └── routes/
│   │       ├── __init__.py
│   │       ├── acte.py
│   │       └── articole.py
│   └── services/
│       ├── __init__.py
│       ├── import_service.py    # CSV/MD → DB
│       └── labeling_service.py  # LLM integration
├── alembic/                 # Database migrations
├── tests/
├── docker-compose.yml
├── Dockerfile
└── requirements.txt

================================================================================
DECIZIE 2: SCHEMA BAZEI DE DATE
================================================================================

OPȚIUNI ANALIZATE:
A) Normalizată (2 tabele: acte + articole)
B) Denormalizată (1 tabel flat)
C) JSONB (PostgreSQL native)

⭐ RECOMANDARE: OPȚIUNEA A - NORMALIZATĂ

MOTIVAȚIE:
+ Evită duplicarea metadatelor actului
+ Ușor de actualizat metadata fără să afectezi articolele
+ Relații clare și performante
+ Queries simple pentru statistici
+ Suport natural pentru versionare

SCHEMA PROPUSĂ:

-- Tabela: acte_legislative
CREATE TABLE acte_legislative (
    id SERIAL PRIMARY KEY,
    tip_act VARCHAR(50) NOT NULL,           -- LEGE, ORDONANȚĂ, etc.
    nr_act VARCHAR(50),                     -- 123, 81, etc.
    data_act DATE,                          -- Data promulgării
    an_act INTEGER,                         -- Anul extras
    titlu_act TEXT NOT NULL,                -- Titlu complet act
    emitent_act VARCHAR(255),               -- Emitent act
    mof_nr VARCHAR(50),                     -- Număr Monitorul Oficial
    mof_data DATE,                          -- Data publicare MOF
    mof_an INTEGER,                         -- Anul MOF
    url_legislatie TEXT,                    -- URL legislatie.just.ro
    html_content TEXT,                      -- HTML original (opțional)
    confidence_score NUMERIC(3,2),          -- Scor parsing (0.00-1.00)
    created_at TIMESTAMP DEFAULT NOW(),
    updated_at TIMESTAMP DEFAULT NOW()
);

-- Index pentru căutări frecvente
CREATE INDEX idx_acte_tip_an ON acte_legislative(tip_act, an_act);
CREATE INDEX idx_acte_mof ON acte_legislative(mof_nr, mof_an);
CREATE INDEX idx_acte_created ON acte_legislative(created_at DESC);

-- Tabela: articole
CREATE TABLE articole (
    id SERIAL PRIMARY KEY,
    act_id INTEGER NOT NULL REFERENCES acte_legislative(id) ON DELETE CASCADE,
    
    -- Identificare articol
    articol_nr VARCHAR(20),                 -- "1", "2^1", "11"
    articol_label VARCHAR(50),              -- "Articolul 1", "Art. 11"
    
    -- Structură ierarhică
    titlu_nr INTEGER,
    titlu_denumire TEXT,
    capitol_nr INTEGER,
    capitol_denumire TEXT,
    sectiune_nr INTEGER,
    sectiune_denumire TEXT,
    subsectiune_nr INTEGER,
    subsectiune_denumire TEXT,
    
    -- Conținut
    text_articol TEXT NOT NULL,             -- Text complet articol
    
    -- LLM Generated (editabile)
    issue TEXT,                             -- Subiect/problemă
    explicatie TEXT,                        -- Explicație detaliată
    
    -- Metadata
    ordine INTEGER,                         -- Ordinea în act (1, 2, 3...)
    created_at TIMESTAMP DEFAULT NOW(),
    updated_at TIMESTAMP DEFAULT NOW()
);

-- Index pentru performance
CREATE INDEX idx_articole_act ON articole(act_id);
CREATE INDEX idx_articole_nr ON articole(act_id, articol_nr);
CREATE INDEX idx_articole_issue ON articole USING gin(to_tsvector('romanian', issue));
CREATE INDEX idx_articole_text ON articole USING gin(to_tsvector('romanian', text_articol));

-- Full-text search support
CREATE INDEX idx_acte_titlu_fts ON acte_legislative USING gin(to_tsvector('romanian', titlu_act));

VERSIONARE (Faza 2 - Opțional):
- Tabela: acte_legislative_versions
- Tracking modificări cu audit trail
- Comparare versiuni diferite ale aceluiași act

================================================================================
DECIZIE 3: INTEGRARE CU APLICAȚIA PRINCIPALĂ
================================================================================

OPȚIUNI ANALIZATE:
A) Aceeași bază de date, schemă separată
B) Bază de date separată complet
C) Aceeași bază, aceleași tabele

⭐ RECOMANDARE: OPȚIUNEA A - ACEEAȘI DB, SCHEMĂ SEPARATĂ

MOTIVAȚIE:
+ O singură conexiune PostgreSQL
+ Ușor de gestionat backups
+ Queries cross-schema posibile (pentru analytics)
+ Izolare logică suficientă
+ Cost redus (un singur server DB)

IMPLEMENTARE:
-- Creează schema separată
CREATE SCHEMA legislatie;

-- Setează search_path
SET search_path TO legislatie, public;

-- Toate tabelele în schema legislatie
CREATE TABLE legislatie.acte_legislative (...);
CREATE TABLE legislatie.articole (...);

CONNECTION STRING:
postgresql://user:password@localhost:5432/monitoring_platform?options=-c%20search_path=legislatie

ALTERNATIVĂ PENTRU DEVELOPMENT:
- DB separată pentru dezvoltare/testare
- Migrare la schema comună în producție

================================================================================
DECIZIE 4: FEATURES MVP vs FAZA 2
================================================================================

⭐ MVP (Minim Viable Product) - 2-3 SĂPTĂMÂNI:

CORE FEATURES:
✅ Import CSV/Markdown → PostgreSQL
✅ CRUD acte legislative (Create, Read, Update, Delete)
✅ CRUD articole
✅ Query by act (toate articolele unui act)
✅ Query by issue (căutare după subiect)
✅ Actualizare issue/explicatie (editare bulk)
✅ Health check endpoint
✅ Basic error handling

API ENDPOINTS MVP:
POST   /api/v1/acte/import              # Import CSV/MD
GET    /api/v1/acte                     # List acte (paginated)
GET    /api/v1/acte/{id}                # Get act by ID
GET    /api/v1/acte/{id}/articole       # Get articole for act
PUT    /api/v1/articole/{id}/labels     # Update issue/explicatie
GET    /api/v1/articole/search          # Search by issue/text
GET    /api/v1/health                   # Health check

FAZA 2 - FEATURES AVANSATE:

ADVANCED SEARCH:
- Full-text search cu PostgreSQL FTS
- Filters complexe (tip_act, an_act, emitent_act)
- Fuzzy search pentru nume acte
- Search in HTML original

LLM INTEGRATION:
- Endpoint pentru labeling batch
- Queue system (Celery/RQ) pentru procesare async
- Rate limiting pentru API-uri externe
- Retry logic cu exponential backoff
- Cost tracking pentru API calls

VERSIONARE:
- Track changes pe acte și articole
- Comparare între versiuni
- Rollback la versiuni anterioare
- Audit trail complet

ANALYTICS:
- Statistici pe tip_act, an_act
- Top issues din legislație
- Coverage metrics (cât % are issue/explicatie)
- Rapoarte pentru monitoring platform

PERFORMANCE:
- Caching cu Redis
- Response pagination
- Query optimization
- Connection pooling

================================================================================
DECIZIE 5: MIGRARE DATE EXISTENTE
================================================================================

OPȚIUNI ANALIZATE:
A) Import batch inițial
B) Scraper integrat direct în DB
C) Hibrid (batch + stream)

⭐ RECOMANDARE: OPȚIUNEA A - IMPORT BATCH INIȚIAL

MOTIVAȚIE:
+ Separare concerns (scraping vs storage)
+ Validare date înainte de import
+ Re-import ușor în caz de probleme
+ CSV/Markdown rămân ca backup

IMPLEMENTARE:

SERVICIU DE IMPORT (import_service.py):
```python
class ImportService:
    async def import_from_csv(self, csv_path: str, md_path: str) -> dict:
        """
        Import act legislativ din CSV + Markdown
        
        Returns:
            {
                'act_id': int,
                'articole_count': int,
                'warnings': []
            }
        """
        
    async def import_directory(self, dir_path: str) -> list:
        """
        Import toate actele dintr-un director
        Găsește perechi CSV/MD automat
        """
        
    async def validate_csv(self, csv_path: str) -> dict:
        """
        Validează CSV înainte de import
        Verifică coloane obligatorii
        """
```

PROCES MIGRARE:
1. Rulează scraper pentru toate actele (7 acte existente)
2. Validează CSV-uri cu quality_checker.py
3. Rulează import_service pentru fiecare act
4. Verifică count-uri (acte importate, articole, etc.)
5. Testează API endpoints cu date reale

SCRIPT MIGRARE:
```bash
# Import toate actele existente
python -m db_service.scripts.migrate_existing \
    --source rezultate/ \
    --db postgresql://user:pass@localhost/db
```

================================================================================
DECIZIE 6: DEPLOYMENT
================================================================================

OPȚIUNI ANALIZATE:
A) Docker Compose (local + staging)
B) Kubernetes (production scale)
C) Serverless (AWS Lambda + RDS)

⭐ RECOMANDARE: OPȚIUNEA A - DOCKER COMPOSE (START)

MOTIVAȚIE:
+ Simplu pentru development
+ Reproducibil pe orice mașină
+ Ușor de testat local
+ Migrare la K8s când e nevoie

DOCKER COMPOSE (docker-compose.yml):
```yaml
version: '3.8'

services:
  postgres:
    image: postgres:15-alpine
    environment:
      POSTGRES_DB: monitoring_platform
      POSTGRES_USER: legislatie_user
      POSTGRES_PASSWORD: ${DB_PASSWORD}
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./init.sql:/docker-entrypoint-initdb.d/init.sql

  api:
    build: .
    ports:
      - "8000:8000"
    environment:
      DATABASE_URL: postgresql://legislatie_user:${DB_PASSWORD}@postgres:5432/monitoring_platform
      API_ENV: development
    depends_on:
      - postgres
    volumes:
      - ./app:/app/app
      - ./alembic:/app/alembic

  pgadmin:
    image: dpage/pgadmin4
    environment:
      PGADMIN_DEFAULT_EMAIL: admin@example.com
      PGADMIN_DEFAULT_PASSWORD: admin
    ports:
      - "5050:80"

volumes:
  postgres_data:
```

COMENZI:
```bash
# Start all services
docker-compose up -d

# Run migrations
docker-compose exec api alembic upgrade head

# Import data
docker-compose exec api python -m scripts.migrate_existing

# View logs
docker-compose logs -f api

# Stop services
docker-compose down
```

PRODUCȚIE (Opțional - Faza 2):
- AWS ECS Fargate / GCP Cloud Run
- Managed PostgreSQL (RDS / Cloud SQL)
- Load balancer + Auto-scaling
- Monitoring cu Prometheus/Grafana

================================================================================
TECH STACK FINAL
================================================================================

BACKEND:
- Python 3.11+
- FastAPI 0.104+ (async web framework)
- SQLAlchemy 2.0+ (ORM)
- Alembic (migrations)
- Pydantic v2 (validation)
- psycopg3 (PostgreSQL driver)

DATABASE:
- PostgreSQL 15+ (JSON support, FTS)
- Schema: legislatie

DEVELOPMENT:
- Docker + Docker Compose
- pytest (testing)
- httpx (async HTTP client for tests)
- black + ruff (code formatting)

OPTIONAL (Faza 2):
- Redis (caching)
- Celery (async tasks)
- Prometheus + Grafana (monitoring)
- Sentry (error tracking)

================================================================================
TIMELINE IMPLEMENTARE
================================================================================

SĂPTĂMÂNA 1: SETUP + MODELS
□ Setup proiect FastAPI + SQLAlchemy
□ Definire modele (acte_legislative, articole)
□ Setup Alembic migrations
□ Docker Compose cu PostgreSQL
□ Tests pentru modele

SĂPTĂMÂNA 2: API ENDPOINTS + IMPORT
□ CRUD endpoints pentru acte
□ CRUD endpoints pentru articole
□ Import service (CSV/MD → DB)
□ Search endpoints
□ Tests pentru API

SĂPTĂMÂNA 3: INTEGRARE + TESTING
□ Import date existente (7 acte)
□ Validare date în DB
□ Integration tests
□ Documentație API (Swagger)
□ Deployment guide

TOTAL: 2-3 SĂPTĂMÂNI PENTRU MVP

================================================================================
EXEMPLE API USAGE
================================================================================

1. IMPORT ACT:
POST /api/v1/acte/import
Body: {
    "csv_path": "/data/LEGE_123_2012.csv",
    "md_path": "/data/LEGE_123_2012.md"
}
Response: {
    "act_id": 1,
    "tip_act": "LEGE",
    "nr_act": "123",
    "articole_count": 359,
    "status": "success"
}

2. GET ACTE (PAGINATED):
GET /api/v1/acte?page=1&size=20&tip_act=LEGE&an_act=2024
Response: {
    "items": [
        {
            "id": 1,
            "tip_act": "LEGE",
            "nr_act": "121",
            "an_act": 2024,
            "titlu_act": "privind energia eoliană offshore",
            "articole_count": 101
        }
    ],
    "total": 150,
    "page": 1,
    "pages": 8
}

3. GET ARTICOLE PENTRU ACT:
GET /api/v1/acte/1/articole?page=1&size=50
Response: {
    "items": [
        {
            "id": 1,
            "articol_nr": "1",
            "articol_label": "Articolul 1",
            "text_articol": "Prezenta lege...",
            "issue": "Obiect și domeniu de aplicare",
            "explicatie": "Articolul definește..."
        }
    ]
}

4. SEARCH BY ISSUE:
GET /api/v1/articole/search?query=energie+regenerabila&limit=20
Response: {
    "items": [
        {
            "id": 45,
            "act": {
                "tip_act": "LEGE",
                "nr_act": "121",
                "titlu_act": "..."
            },
            "articol_nr": "5",
            "issue": "Energie regenerabilă offshore",
            "relevance_score": 0.95
        }
    ]
}

5. UPDATE LABELS (pentru LLM):
PUT /api/v1/articole/45/labels
Body: {
    "issue": "Noul issue generat de LLM",
    "explicatie": "Noua explicație"
}
Response: {
    "id": 45,
    "updated": true
}

6. BATCH UPDATE (pentru procesare LLM):
POST /api/v1/articole/batch-update
Body: {
    "updates": [
        {"id": 45, "issue": "...", "explicatie": "..."},
        {"id": 46, "issue": "...", "explicatie": "..."}
    ]
}
Response: {
    "updated_count": 2,
    "errors": []
}

================================================================================
NEXT STEPS
================================================================================

IMEDIAT (După Aprobare):
1. ✅ Standardizare terminologie (DONE: denumire→titlu_act, emitent→emitent_act)
2. □ Creare structură proiect db_service/
3. □ Setup Docker Compose cu PostgreSQL
4. □ Definire modele SQLAlchemy
5. □ Prima migrație Alembic

SĂPTĂMÂNA VIITOARE:
6. □ Implementare endpoints CRUD
7. □ Serviciu de import CSV/MD
8. □ Testare cu 7 acte existente
9. □ Documentație API

================================================================================
ÎNTREBĂRI CHEIE PENTRU CLIENT
================================================================================

1. PRIORITATE:
   - Este prioritar MVP-ul (2-3 săptămâni) sau vrei și features avansate?
   - Care e deadline-ul pentru integrare cu monitoring platform?

2. INFRASTRUCTURE:
   - Există deja un server PostgreSQL pentru monitoring_platform?
   - Preferi schema separată sau DB separată?
   - Cloud provider preferat (AWS/GCP/Azure/Local)?

3. LLM INTEGRATION:
   - Care serviciu LLM: ChatGPT (OpenAI) sau Gemini (Google)?
   - Buget pentru API calls?
   - Procesare sync sau async (queue)?

4. VERSIONARE:
   - E nevoie de tracking pentru modificări acte legislative?
   - Audit trail complet sau simplu?

5. PERFORMANCE:
   - Cât de multe query-uri simultan (10/sec, 100/sec)?
   - E nevoie de caching?

================================================================================
RESURSE NECESARE
================================================================================

DEVELOPMENT:
- 1 developer backend (Python/FastAPI)
- Access la server PostgreSQL
- Docker Desktop pentru local development
- IDE (VSCode/PyCharm)

INFRASTRUCTURE (MVP):
- Server PostgreSQL 15+ (2GB RAM, 20GB disk)
- Server pentru FastAPI (1GB RAM)
- Docker Compose setup

INFRASTRUCTURE (Production):
- Managed PostgreSQL (RDS/Cloud SQL)
- Container hosting (ECS/Cloud Run)
- Load balancer
- Monitoring (Prometheus/Grafana)

COSTURI ESTIMATE (Cloud):
MVP:
- PostgreSQL RDS (db.t3.micro): ~$15/lună
- ECS Fargate (0.25 vCPU): ~$10/lună
- Total: ~$25/lună

Production:
- PostgreSQL RDS (db.t3.small): ~$30/lună
- ECS Fargate (0.5 vCPU): ~$20/lună
- Load Balancer: ~$20/lună
- Total: ~$70/lună

================================================================================
CONTACT & SUPPORT
================================================================================

DOCUMENTAȚIE:
- FastAPI: https://fastapi.tiangolo.com
- SQLAlchemy: https://docs.sqlalchemy.org
- PostgreSQL: https://www.postgresql.org/docs/

REPOSITORY:
- Branch: feature/database-integration
- Documentation: /docs/database/
- API Docs: http://localhost:8000/docs (după deployment)

================================================================================
FIN DOCUMENT
================================================================================

Versiune: 1.0
Data: 7 Noiembrie 2025
Status: Ready for Implementation

Următorul pas: Aprobare strategie și începere implementare
