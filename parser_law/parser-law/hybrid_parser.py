#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
Parser simplificat pentru actele legislative - foloseÈ™te doar strategia HTML CSS care funcÈ›ioneazÄƒ perfect
Cod redus cu ~60% faÈ›Äƒ de versiunea anterioarÄƒ, menÈ›inÃ¢nd 100% funcÈ›ionalitatea
"""

import re
import pandas as pd
from typing import Dict, List, Optional, Any, Tuple
from bs4 import BeautifulSoup
import logging
import os
import json
from datetime import datetime

from html_parser import parse_html_legislative_structure

# Configurare logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def int_to_roman(num: int) -> str:
    """ConverteÈ™te un numÄƒr Ã®ntreg Ã®n cifre romane"""
    if pd.isna(num) or num == 0:
        return ''
    
    num = int(num)
    val = [
        1000, 900, 500, 400,
        100, 90, 50, 40,
        10, 9, 5, 4,
        1
    ]
    syms = [
        'M', 'CM', 'D', 'CD',
        'C', 'XC', 'L', 'XL',
        'X', 'IX', 'V', 'IV',
        'I'
    ]
    roman_num = ''
    i = 0
    while num > 0:
        for _ in range(num // val[i]):
            roman_num += syms[i]
            num -= val[i]
        i += 1
    return roman_num

def format_article_text_for_markdown(text: str) -> str:
    """
    FormateazÄƒ textul articolului pentru Markdown:
    - Alineate: (1), (2), etc. pe rÃ¢nduri separate
    - Litere: a), b), c) pe rÃ¢nduri separate cu indentare
    - Separatorul ... devine newline
    """
    if not text or text == '*[ConÈ›inut lipsÄƒ]*':
        return text
    
    # Mai Ã®ntÃ¢i, trateazÄƒ cazul cÃ¢nd o literÄƒ vine direct dupÄƒ : fÄƒrÄƒ ...
    # Ex: "atribuÈ›ii:a)text" -> "atribuÈ›ii:\n\n  **a)** text"
    text = re.sub(r':([a-z]\))', r':\n\n  **\1**', text)
    
    # Split pe separator ... pentru litere/alineate
    parts = text.split('...')
    
    formatted_lines = []
    for i, part in enumerate(parts):
        part = part.strip()
        if not part:
            continue
        
        # DetecteazÄƒ dacÄƒ Ã®ncepe cu literÄƒ: a), b), c), etc.
        letter_match = re.match(r'^([a-z]\))', part)
        if letter_match:
            # DacÄƒ litera e deja formatatÄƒ cu ** din regex-ul de mai sus, nu o formata din nou
            if not part.startswith('**'):
                formatted_lines.append(f"  **{letter_match.group(1)}** {part[2:].strip()}")
            else:
                formatted_lines.append(f"  {part}")
        # DetecteazÄƒ dacÄƒ Ã®ncepe cu alineat: (1), (2), etc.
        elif re.match(r'^\(\d+\)', part):
            formatted_lines.append(f"\n{part}")
        else:
            formatted_lines.append(part)
    
    return '\n\n'.join(formatted_lines) if formatted_lines else text

class HybridLegislativeParser:
    """
    Parser simplificat care foloseÈ™te doar strategia HTML CSS (optimÄƒ pentru 95% din documente)
    """
    
    def __init__(self, config: Optional[Dict[str, Any]] = None):
        """IniÈ›ializeazÄƒ parserul cu configuraÈ›ie"""
        self.config = config or {}
        self.debug_mode = self.config.get('debug', False)
    
    def parse(self, content: str, content_type: str = 'auto') -> Tuple[pd.DataFrame, Dict[str, Any]]:
        """
        ParseazÄƒ conÈ›inutul folosind strategia HTML CSS
        
        Args:
            content: ConÈ›inutul de parsat (HTML)
            content_type: 'html' sau 'auto' pentru detectare automatÄƒ
            
        Returns:
            Tuple cu (DataFrame cu rezultate, metrici de parsare)
        """
        
        # DetecteazÄƒ tipul conÈ›inutului dacÄƒ e setat pe auto
        if content_type == 'auto':
            content_type = self._detect_content_type(content)
        
        logger.info(f"ğŸš€ Ãncep parsarea pentru conÈ›inut de tip: {content_type}")
        
        metrics = {
            'content_type': content_type,
            'strategy_used': 'html_css_specific',
            'confidence': 0.0,
            'total_elements': 0,
            'parsing_errors': []
        }
        
        if content_type != 'html':
            logger.warning("âš ï¸ ConÈ›inutul nu este HTML")
            return pd.DataFrame(), metrics
        
        try:
            # Parsare HTML cu CSS
            df = parse_html_legislative_structure(content)
            
            if df.empty:
                logger.warning("âš ï¸ Nu s-au gÄƒsit date parsabile Ã®n document")
                return pd.DataFrame(), metrics
            
            # Extrage metadata È™i o adaugÄƒ la toate rÃ¢ndurile
            soup = BeautifulSoup(content, 'html.parser')
            metadata = self._extract_html_metadata(soup)
            
            # Mapare lowercase -> uppercase (pentru verificare)
            col_uppercase_map = {
                'tip_act': 'Tip_Act',
                'nr_act': 'Nr',
                'data_act': 'Data_An',
                'denumire': 'Denumire',
                'mof_nr': 'Mof_nr',
                'mof_data': 'Mof_Data'
            }
            
            # AdaugÄƒ metadata DOAR dacÄƒ nu existÄƒ deja Ã®n nicio variantÄƒ (lowercase sau uppercase)
            for col, value in metadata.items():
                uppercase_col = col_uppercase_map.get(col, col)
                
                # VerificÄƒ dacÄƒ existÄƒ Ã®n uppercase SAU lowercase
                has_uppercase = uppercase_col in df.columns and not df[uppercase_col].isna().all()
                has_lowercase = col in df.columns and not df[col].isna().all()
                
                # AdaugÄƒ DOAR dacÄƒ nu existÄƒ Ã®n NICIO variantÄƒ
                if not has_uppercase and not has_lowercase:
                    if col not in df.columns:
                        df[col] = value
            
            df = self._post_process_results(df)
            
            # Validare structuralÄƒ post-extracÈ›ie
            validation_results = self._validate_extraction(df)
            
            # CalculeazÄƒ confidence
            confidence = df['confidence_score'].iloc[0] if 'confidence_score' in df.columns else 0.0
            
            metrics['confidence'] = confidence
            metrics['total_elements'] = len(df)
            metrics['validation'] = validation_results
            
            logger.info(f"ğŸ¯ Parsare finalizatÄƒ:")
            logger.info(f"   â€¢ Confidence: {confidence:.2f}")
            logger.info(f"   â€¢ Elemente extrase: {len(df)}")
            if not validation_results['is_valid']:
                logger.warning(f"   âš ï¸  Validare: {len(validation_results['issues'])} issues detectate")
            
            return df, metrics
                
        except Exception as e:
            error_msg = f"Eroare la parsare: {str(e)}"
            logger.error(error_msg)
            metrics['parsing_errors'].append(error_msg)
            return pd.DataFrame(), metrics
    
    def _detect_content_type(self, content: str) -> str:
        """DetecteazÄƒ tipul conÈ›inutului"""
        content_lower = content.lower().strip()
        
        if content_lower.startswith('<!doctype') or content_lower.startswith('<html'):
            return 'html'
        elif '<div' in content_lower and 'class=' in content_lower:
            return 'html'
        else:
            return 'text'
    
    def _extract_html_metadata(self, soup: BeautifulSoup) -> Dict[str, Any]:
        """
        Extrage metadata suplimentarÄƒ din HTML (denumire, emitent, MOF).
        Metadata principalÄƒ (tip_act, nr_act, data_act) este deja extrasÄƒ Ã®n html_parser.
        """
        metadata: Dict[str, Any] = {
            'denumire': None,
            'emitent': None,
            'mof_nr': None,
            'mof_data': None
        }
        
        # Extrage denumirea din clasa S_HDR: "privind energia eolianÄƒ offshore"
        s_hdr = soup.find('span', class_='S_HDR')
        if s_hdr:
            metadata['denumire'] = s_hdr.get_text(strip=True)
        
        # Extrage emitentul din clasa S_EMT_BDY: "PARLAMENTUL ROMÃ‚NIEI"
        s_emt_bdy = soup.find('span', class_='S_EMT_BDY')
        if s_emt_bdy:
            metadata['emitent'] = s_emt_bdy.get_text(strip=True)
        
        # Extrage info MOF din clasa S_PUB_BDY: "MONITORUL OFICIAL nr. 421 din 8 mai 2024"
        s_pub_bdy = soup.find('span', class_='S_PUB_BDY')
        if s_pub_bdy:
            text = s_pub_bdy.get_text(strip=True)
            
            # Extrage numÄƒrul Monitorului Oficial
            match_mof_nr = re.search(r'nr\.?\s*(\d+)', text, re.I)
            if match_mof_nr:
                metadata['mof_nr'] = int(match_mof_nr.group(1))
            
            # Extrage data publicÄƒrii Ã®n MOF
            match_mof_data = re.search(r'din\s+(\d+)\s+(\w+)\s+(\d{4})', text, re.I)
            if match_mof_data:
                zi, luna, an = match_mof_data.groups()
                
                luni_map = {
                    'ianuarie': '01', 'februarie': '02', 'martie': '03', 'aprilie': '04',
                    'mai': '05', 'iunie': '06', 'iulie': '07', 'august': '08',
                    'septembrie': '09', 'octombrie': '10', 'noiembrie': '11', 'decembrie': '12'
                }
                luna_nr = luni_map.get(luna.lower(), '01')
                metadata['mof_data'] = f"{zi.zfill(2)}/{luna_nr}/{an}"
        
        return metadata
    
    def _validate_extraction(self, df: pd.DataFrame) -> Dict[str, Any]:
        """
        ValideazÄƒ calitatea extracÈ›iei È™i detecteazÄƒ probleme potenÈ›iale.
        
        Returns:
            Dict cu is_valid, issues (listÄƒ), quality_score (0-1)
        """
        issues = []
        
        if df.empty:
            return {
                'is_valid': False,
                'issues': ['DataFrame gol - nicio extracÈ›ie'],
                'quality_score': 0.0
            }
        
        # VerificÄƒ duplicates la art_nr
        if 'art_nr' in df.columns:
            duplicates = df[df['art_nr'].duplicated(keep=False)]['art_nr'].dropna().unique()
            if len(duplicates) > 0:
                issues.append(f"Articole duplicate: {list(duplicates)}")
        
        # VerificÄƒ secvenÈ›Äƒ articole (lipsÄƒ numere)
        if 'art_nr' in df.columns:
            art_numbers = sorted(df['art_nr'].dropna().unique())
            if len(art_numbers) > 1:
                expected = list(range(int(art_numbers[0]), int(art_numbers[-1]) + 1))
                missing = [n for n in expected if n not in art_numbers]
                if missing:
                    issues.append(f"Articole lipsÄƒ din secvenÈ›Äƒ: {missing}")
        
        # VerificÄƒ articole cu text prea scurt (< 10 caractere)
        if 'text_articol' in df.columns and 'art_nr' in df.columns:
            short_texts = df[df['text_articol'].str.len() < 10]
            if not short_texts.empty:
                short_arts = short_texts['art_nr'].tolist()
                issues.append(f"Articole cu text prea scurt: {short_arts}")
        
        # CalculeazÄƒ quality score
        quality_score = 1.0 - (len(issues) * 0.15)  # -0.15 pentru fiecare issue
        quality_score = max(0.0, quality_score)  # Nu poate fi negativ
        
        return {
            'is_valid': len(issues) == 0,
            'issues': issues,
            'quality_score': round(quality_score, 2)
        }
    
    def _post_process_results(self, df: pd.DataFrame) -> pd.DataFrame:
        """Post-proceseazÄƒ rezultatele pentru consistenÈ›Äƒ"""
        if df.empty:
            return df
        
        # Mapare coloane vechi (UpperCase/MixedCase) -> coloane noi (lowercase_underscore)
        old_to_new = {
            'Tip_Act': 'tip_act',
            'Nr': 'nr_act', 
            'Data_An': 'data_act',
            'Denumire': 'denumire',
            'Mof_nr': 'mof_nr',
            'Mof_Data': 'mof_data',
            'Mof_An': 'mof_an',
            'Emitent': 'emitent',
            'Titlu_Nr': 'titlu_nr',
            'Titlu_Denumire': 'titlu_denumire',
            'Capitol_Nr': 'capitol_nr',
            'Capitol_Denumire': 'capitol_denumire',
            'Sectiune_Nr': 'sectiune_nr',
            'Sectiune_Denumire': 'sectiune_denumire',
            'Subsectiune_Nr': 'subsectiune_nr',
            'Subsectiune_Denumire': 'subsectiune_denumire',
            'Art.1': 'art_nr',
            'Art.2': 'art_idx',
            'Articol_Label': 'articol_label',
            'Text_Articol': 'text_articol'
        }
        
        # RedenumeÈ™te coloanele vechi Ã®n cele noi
        rename_map = {}
        for old_col, new_col in old_to_new.items():
            if old_col in df.columns:
                # DacÄƒ existÄƒ ambele, vom È™terge pe cea veche mai jos
                # DacÄƒ existÄƒ doar cea veche, o redenumim
                if new_col not in df.columns:
                    rename_map[old_col] = new_col
        
        if rename_map:
            df = df.rename(columns=rename_map)
        
        # EliminÄƒ coloanele duplicate (doar cele vechi dacÄƒ existÄƒ ambele)
        columns_to_remove = []
        for old_col, new_col in old_to_new.items():
            if old_col in df.columns and new_col in df.columns:
                columns_to_remove.append(old_col)
        
        # EliminÄƒ coloana art_idx (fost Art.2) - nu Ã®È™i are rostul
        if 'art_idx' in df.columns:
            columns_to_remove.append('art_idx')
        if 'Art.2' in df.columns:
            columns_to_remove.append('Art.2')
        
        if columns_to_remove:
            df = df.drop(columns=columns_to_remove)
        
        # FuncÈ›ie helper pentru extragere an cu validare
        def extract_year(date_str):
            """Extrage anul din datÄƒ (formate: DD/MM/YYYY, DD/luna/YYYY, YYYY)"""
            if pd.isna(date_str) or not date_str:
                return None
            
            try:
                date_str = str(date_str).strip()
                # CautÄƒ pattern de 4 cifre pentru an
                match = re.search(r'\b(\d{4})\b', date_str)
                if match:
                    year = int(match.group(1))
                    # Validare: anii Ã®ntre 1900-2100 (legislaÈ›ie romÃ¢neascÄƒ modernÄƒ)
                    if 1900 <= year <= 2100:
                        return year
                    else:
                        logging.warning(f"An invalid detectat: {year} din '{date_str}'")
                        return None
                return None
            except (ValueError, AttributeError) as e:
                logging.warning(f"Eroare la extragerea anului din '{date_str}': {e}")
                return None
        
        # Extrage an_act din data_act
        if 'data_act' in df.columns:
            df['an_act'] = df['data_act'].apply(extract_year)
        
        # Extrage mof_an din mof_data
        if 'mof_data' in df.columns:
            df['mof_an'] = df['mof_data'].apply(extract_year)
        
        # CurÄƒÈ›Äƒm articol_label - pÄƒstrÄƒm doar "Articolul X"
        if 'articol_label' in df.columns:
            def extract_article_label(text):
                match = re.match(r'(Articolul\s+\d+)', str(text))
                return match.group(1) if match else str(text)
            
            df['articol_label'] = df['articol_label'].apply(extract_article_label)
        
        # SorteazÄƒ dupÄƒ numÄƒrul articolului
        if 'art_nr' in df.columns:
            df['art_nr'] = pd.to_numeric(df['art_nr'], errors='coerce').fillna(0).astype(int)
            df = df.sort_values('art_nr').reset_index(drop=True)
        
        # EliminÄƒm duplicatele - pÄƒstrÄƒm intrarea cu cel mai mult conÈ›inut Ã®n text_articol
        if 'art_nr' in df.columns and 'text_articol' in df.columns:
            df['_text_length'] = df['text_articol'].astype(str).str.len()
            df = df.sort_values(['art_nr', '_text_length'], ascending=[True, False])
            df = df.drop_duplicates(subset=['art_nr'], keep='first')
            df = df.drop(columns=['_text_length'])
            df = df.reset_index(drop=True)
        
        # CurÄƒÈ›Äƒm text_articol - eliminÄƒm label-ul din text dacÄƒ existÄƒ
        if 'text_articol' in df.columns and 'articol_label' in df.columns:
            def clean_text(row):
                text = str(row['text_articol'])
                label = str(row['articol_label'])
                if text.startswith(label):
                    text = text[len(label):].strip()
                return text
            
            df['text_articol'] = df.apply(clean_text, axis=1)
        
        # CurÄƒÈ›Äƒ textul final
        if 'text_articol' in df.columns:
            df['text_articol'] = df['text_articol'].astype(str).str.strip()
        
        # AdaugÄƒ coloane pentru Issue È™i ExplicaÈ›ie (vor fi completate manual)
        if 'issue' not in df.columns:
            df['issue'] = ''
        if 'explicatie' not in df.columns:
            df['explicatie'] = ''
        
        # ConverteÈ™te numerele Ã®n romane pentru titlu_nr, capitol_nr, sectiune_nr
        for col in ['titlu_nr', 'capitol_nr', 'sectiune_nr', 'subsectiune_nr']:
            if col in df.columns:
                df[col] = df[col].apply(lambda x: int_to_roman(x) if pd.notna(x) and x != 0 else '')
        
        # ReordoneazÄƒ coloanele: metadata la Ã®nceput, apoi restul
        metadata_cols = ['tip_act', 'nr_act', 'data_act', 'an_act', 'denumire', 'emitent', 'mof_nr', 'mof_data', 'mof_an']
        first_cols = [col for col in metadata_cols if col in df.columns]
        
        # Coloane structurale
        structural_cols = ['titlu_nr', 'titlu_denumire', 'capitol_nr', 'capitol_denumire', 
                          'sectiune_nr', 'sectiune_denumire', 'subsectiune_nr', 'subsectiune_denumire']
        middle_cols = [col for col in structural_cols if col in df.columns]
        
        # Coloane de articol
        article_cols = ['art_nr', 'articol_label', 'text_articol', 'issue', 'explicatie']
        last_cols = [col for col in article_cols if col in df.columns]
        
        # Restul coloanelor
        other_cols = [col for col in df.columns 
                     if col not in first_cols + middle_cols + last_cols]
        
        # ReordoneazÄƒ
        df = df[first_cols + middle_cols + last_cols + other_cols]
        
        return df
    
    def _generate_statistics(self, df: pd.DataFrame, validation: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
        """GenereazÄƒ statistici despre rezultatele parsÄƒrii"""
        stats = {
            'total_articole': len(df),
            'articole_cu_continut': len(df[df['text_articol'].str.len() > 10]) if 'text_articol' in df.columns else 0,
            'total_caractere': int(df['text_articol'].str.len().sum()) if 'text_articol' in df.columns else 0,
            'lungime_medie': float(df['text_articol'].str.len().mean()) if 'text_articol' in df.columns else 0.0,
            'capitole_identificate': int(df['capitol_nr'].nunique()) if 'capitol_nr' in df.columns else 0,
            'sectiuni_identificate': int(df['sectiune_nr'].nunique()) if 'sectiune_nr' in df.columns else 0
        }
        
        # AdaugÄƒ validation dacÄƒ existÄƒ
        if validation:
            stats['validation'] = validation
        
        return stats
    
    def _format_article_text(self, text: str) -> str:
        """
        FormateazÄƒ textul articolului pentru lizibilitate Ã®n Markdown
        - Pune fiecare alineat (1), (2), etc. pe rÃ¢nd nou
        - Pune fiecare literÄƒ a), b), c) pe rÃ¢nd nou È™i indentatÄƒ
        
        Args:
            text: Textul brut al articolului
            
        Returns:
            Text formatat cu alineate È™i litere pe rÃ¢nduri separate
        """
        if not text:
            return text
        
        # VerificÄƒ dacÄƒ Ã®ncepe cu alineat (1), (2), etc.
        if not re.match(r'^\(\d+\)\s+[A-ZÄ‚ÃÃ‚È˜Èš]', text):
            # Nu Ã®ncepe cu alineat - verificÄƒ dacÄƒ are litere cu separator ";..."
            if ';...' in text:
                return self._format_litere(text)
            return text.strip()
        
        # Are alineate - split pe pattern care prinde doar alineate urmate de majusculÄƒ
        # Regex: (cifrÄƒ) urmat de spaÈ›iu È™i majusculÄƒ (Ã®nceputul unei propoziÈ›ii)
        parts = re.split(r'\((\d+)\)\s+(?=[A-ZÄ‚ÃÃ‚È˜Èš])', text)
        
        formatted_lines = []
        
        # Prima parte (Ã®nainte de primul alineat) - de obicei goalÄƒ
        if parts[0].strip():
            formatted_lines.append(parts[0].strip())
            formatted_lines.append("")
        
        # ProceseazÄƒ perechi (numÄƒr alineat, conÈ›inut alineat)
        for i in range(1, len(parts), 2):
            if i + 1 < len(parts):
                alineat_nr = parts[i]
                alineat_text = parts[i + 1].strip()
                
                # FormateazÄƒ literele din alineat (dacÄƒ are)
                formatted_alineat = self._format_litere(alineat_text)
                
                # Pune alineatul bold pe linie separatÄƒ, apoi conÈ›inutul
                formatted_lines.append(f"**({alineat_nr})**")
                formatted_lines.append(formatted_alineat)
                formatted_lines.append("")
        
        return "\n".join(formatted_lines).strip()
    
    def _format_litere(self, text: str) -> str:
        """
        FormateazÄƒ literele a), b), c), ..., È™), È›) din text
        Pune fiecare literÄƒ pe rÃ¢nd nou È™i indentatÄƒ
        
        Literele sunt marcate Ã®n HTML cu S_LIT_TTL È™i au separator ";..." Ã®ntre ele
        
        IMPORTANT: O enumerare realÄƒ Ã®ncepe Ã®ntotdeauna cu litera a)
        DacÄƒ textul conÈ›ine doar referinÈ›e la litere (ex: "lit. d)") fÄƒrÄƒ sÄƒ Ã®nceapÄƒ 
        enumerarea cu a), atunci nu este o enumerare realÄƒ È™i nu trebuie formatat.
        
        Args:
            text: Text care poate conÈ›ine litere
            
        Returns:
            Text cu litere formatate
        """
        if not text:
            return text
        
        # VerificÄƒ dacÄƒ are separatorul de litere ";..."
        if ';...' in text:
            logger.debug(f"_format_litere: GÄƒsit separator ;... Ã®n text de lungime {len(text)}")
            
            # VerificÄƒ dacÄƒ existÄƒ litera a) Ã®n text - indicator de enumerare realÄƒ
            # Pattern: a) urmat de orice caracter (nu necesitÄƒ spaÈ›iu)
            # DAR nu precedat de "lit." sau "lit:" - acestea sunt referinÈ›e, nu enumerÄƒri
            a_match = re.search(r'a\)', text, re.IGNORECASE)
            if not a_match:
                # Nu are litera a) - probabil sunt doar referinÈ›e (ex: "lit. d)")
                logger.debug("_format_litere: Nu am gÄƒsit litera a) - nu este enumerare realÄƒ")
                return text.strip()
            
            # VerificÄƒ contextul din jurul lui a) pentru a determina dacÄƒ e referinÈ›Äƒ sau enumerare
            start_pos = max(0, a_match.start() - 10)
            context_before = text[start_pos:a_match.start()].lower()
            
            # DacÄƒ a) este precedat imediat de "lit." sau "lit:", e o referinÈ›Äƒ, nu enumerare
            if re.search(r'lit\.?\s*$', context_before):
                logger.debug("_format_litere: a) este precedat de 'lit.' - este referinÈ›Äƒ, nu enumerare")
                return text.strip()
            
            # Split pe ";..." pentru a separa literele
            parts = text.split(';...')
            formatted = []
            
            for i, part in enumerate(parts):
                part = part.strip()
                if not part:
                    continue
                
                if i == 0:
                    # Prima parte - poate conÈ›ine introducerea + prima literÄƒ
                    # CautÄƒ prima literÄƒ Ã®n text
                    match = re.search(r'([a-zÄƒÃ¢Ã®È™È›]\))(.+)$', part, re.IGNORECASE | re.DOTALL)
                    if match:
                        # Are literÄƒ - separÄƒ introducerea de literÄƒ
                        intro_end = match.start()
                        if intro_end > 0:
                            intro = part[:intro_end].rstrip(':').strip()
                            if intro:
                                formatted.append(intro + ':')
                        
                        # AdaugÄƒ prima literÄƒ
                        litera = match.group(1)
                        litera_text = match.group(2).strip()
                        formatted.append(f"\n  **{litera}** {litera_text}")
                    else:
                        # Nu are literÄƒ - e doar introducere
                        intro = part.rstrip(':').strip()
                        if intro:
                            formatted.append(intro + ':')
                else:
                    # PÄƒrÈ›ile urmÄƒtoare - fiecare ar trebui sÄƒ Ã®nceapÄƒ cu literÄƒ)
                    match = re.match(r'^([a-zÄƒÃ¢Ã®È™È›]\))\s*(.+)$', part, re.IGNORECASE | re.DOTALL)
                    
                    if match:
                        # E o literÄƒ
                        litera = match.group(1)
                        litera_text = match.group(2).strip()
                        formatted.append(f"\n  **{litera}** {litera_text}")
                    else:
                        # Nu e literÄƒ - text dupÄƒ ultima literÄƒ
                        if part and part not in [':', ';', '.', '...']:
                            formatted.append(f"\n\n{part}")
            
            return "".join(formatted) if formatted else text.strip()
        else:
            # Nu are ";..." - returneazÄƒ textul neschimbat
            # Nu Ã®ncercÄƒm sÄƒ detectÄƒm litere standalone pentru cÄƒ riscÄƒm false positives
            return text.strip()
            
            return "".join(formatted) if formatted else text.strip()
    
    def _generate_markdown(self, df: pd.DataFrame) -> str:
        """
        GenereazÄƒ conÈ›inut Markdown optimizat pentru RAG È™i vector databases
        
        Args:
            df: DataFrame cu articolele parsate
            
        Returns:
            String cu conÈ›inutul Markdown structurat
        """
        if df.empty:
            return "# Document gol\n\nNu s-au gÄƒsit articole."
        
        lines = []
        
        # YAML Frontmatter - metadata globalÄƒ
        first_row = df.iloc[0]
        lines.append("---")
        lines.append(f"tip_act: {first_row.get('tip_act', 'N/A')}")
        lines.append(f"nr_act: {first_row.get('nr_act', 'N/A')}")
        lines.append(f"data_act: {first_row.get('data_act', 'N/A')}")
        lines.append(f"an_act: {first_row.get('an_act', 'N/A')}")
        lines.append(f"emitent: {first_row.get('emitent', 'N/A')}")
        lines.append(f'denumire: "{first_row.get("denumire", "N/A")}"')
        lines.append(f"mof_nr: {first_row.get('mof_nr', 'N/A')}")
        lines.append(f"mof_data: {first_row.get('mof_data', 'N/A')}")
        lines.append(f"mof_an: {first_row.get('mof_an', 'N/A')}")
        lines.append(f"total_articole: {len(df)}")
        lines.append("---")
        lines.append("")
        
        # Titlu principal
        tip_act = first_row.get('tip_act', 'ACT NORMATIV')
        nr_act = first_row.get('nr_act', '')
        data_act = first_row.get('data_act', '')
        
        if nr_act:
            lines.append(f"# {tip_act} nr. {nr_act} din {data_act}")
        else:
            lines.append(f"# {tip_act} din {data_act}")
        lines.append("")
        
        if first_row.get('emitent'):
            lines.append(f"**Emitent:** {first_row.get('emitent')}")
        if first_row.get('mof_nr'):
            lines.append(f"**Publicat Ã®n:** Monitorul Oficial nr. {first_row.get('mof_nr')} din {first_row.get('mof_data')}")
        lines.append("")
        
        if first_row.get('denumire'):
            lines.append("## Denumire")
            lines.append(first_row.get('denumire'))
            lines.append("")
        
        lines.append("---")
        lines.append("")
        
        # INDEX STRUCTURAT
        lines.append("# INDEX")
        lines.append("")
        
        # ConstruieÈ™te index ierarhic
        current_titlu = None
        current_capitol = None
        current_sectiune = None
        current_subsectiune = None
        
        for idx, row in df.iterrows():
            # ConstruieÈ™te ierarhia din coloane
            titlu = ''
            capitol = ''
            sectiune = ''
            subsectiune = ''
            
            if row.get('titlu_denumire'):
                titlu_nr = row.get('titlu_nr', '')
                titlu_den = row.get('titlu_denumire', '')
                titlu = f"TITLUL {titlu_nr} - {titlu_den}" if titlu_nr else titlu_den
            
            if row.get('capitol_denumire'):
                capitol_nr = row.get('capitol_nr', '')
                capitol_den = row.get('capitol_denumire', '')
                capitol = f"CAPITOLUL {capitol_nr} - {capitol_den}" if capitol_nr else capitol_den
            
            if row.get('sectiune_denumire'):
                sectiune_nr = row.get('sectiune_nr', '')
                sectiune_den = row.get('sectiune_denumire', '')
                sectiune = f"SECÈšIUNEA {sectiune_nr} - {sectiune_den}" if sectiune_nr else sectiune_den
            
            if row.get('subsectiune_denumire'):
                subsectiune_nr = row.get('subsectiune_nr', '')
                subsectiune_den = row.get('subsectiune_denumire', '')
                subsectiune = f"SUBSECÈšIUNEA {subsectiune_nr} - {subsectiune_den}" if subsectiune_nr else subsectiune_den
            
            nr_articol = row.get('art_nr', row.get('nr_articol', ''))
            
            # Titlu nou
            if titlu and titlu != current_titlu:
                lines.append(f"## {titlu}")
                current_titlu = titlu
                current_capitol = None
                current_sectiune = None
                current_subsectiune = None
            
            # Capitol nou
            if capitol and capitol != current_capitol:
                lines.append(f"### {capitol}")
                current_capitol = capitol
                current_sectiune = None
                current_subsectiune = None
            
            # SecÈ›iune nouÄƒ
            if sectiune and sectiune != current_sectiune:
                lines.append(f"#### {sectiune}")
                current_sectiune = sectiune
                current_subsectiune = None
            
            # SubsecÈ›iune nouÄƒ
            if subsectiune and subsectiune != current_subsectiune:
                lines.append(f"##### {subsectiune}")
                current_subsectiune = subsectiune
            
            # Articol
            if nr_articol:
                lines.append(f"- [Art. {nr_articol}](#art-{nr_articol}) - *[Issue: TODO]*")
        
        lines.append("")
        lines.append("---")
        lines.append("")
        
        # CHUNKS - fiecare articol
        lines.append("# ARTICOLE")
        lines.append("")
        
        for idx, row in df.iterrows():
            nr_articol = row.get('art_nr', row.get('nr_articol', ''))
            text_articol = row.get('text_articol', '')
            
            # ConstruieÈ™te context ierarhic complet
            titlu = ''
            capitol = ''
            sectiune = ''
            
            # VerificÄƒ mai multe variante de nume coloane
            if row.get('titlu_denumire'):
                titlu_nr = row.get('titlu_nr', '')
                titlu_den = row.get('titlu_denumire', '')
                titlu = f"TITLUL {titlu_nr} - {titlu_den}" if titlu_nr else titlu_den
            elif row.get('titlu'):
                titlu = row.get('titlu')
            
            if row.get('capitol_denumire'):
                capitol_nr = row.get('capitol_nr', '')
                capitol_den = row.get('capitol_denumire', '')
                capitol = f"CAPITOLUL {capitol_nr} - {capitol_den}" if capitol_nr else capitol_den
            elif row.get('capitol'):
                capitol = row.get('capitol')
            
            if row.get('sectiune_denumire'):
                sectiune_nr = row.get('sectiune_nr', '')
                sectiune_den = row.get('sectiune_denumire', '')
                sectiune = f"SECÈšIUNEA {sectiune_nr} - {sectiune_den}" if sectiune_nr else sectiune_den
            elif row.get('sectiune'):
                sectiune = row.get('sectiune')
            
            # Header articol
            if nr_articol:
                lines.append(f'<a id="art-{nr_articol}"></a>')
                lines.append(f"## Art. {nr_articol}")
            else:
                idx_num = int(idx) if isinstance(idx, (int, float)) else 0
                lines.append(f'<a id="art-{idx_num + 1}"></a>')
                lines.append(f"## Art. {idx_num + 1}")
            lines.append("")
            
            # Context ierarhic
            context_parts = []
            if titlu:
                context_parts.append(titlu)
            if capitol:
                context_parts.append(capitol)
            if sectiune:
                context_parts.append(sectiune)
            
            if context_parts:
                lines.append(f"**Context ierarhic:** {' / '.join(context_parts)}")
                lines.append("")
            
            # Issue placeholder
            lines.append("**Issue:** *[TODO - adaugÄƒ descriere scurtÄƒ]*")
            lines.append("")
            
            # ExplicaÈ›ie placeholder
            lines.append("**ExplicaÈ›ie:** *[TODO - adaugÄƒ explicaÈ›ie Ã®n 1-2 fraze, limbaj simplu]*")
            lines.append("")
            
            # Metadata structuratÄƒ pentru embedding
            lines.append("**Metadata:**")
            lines.append("```yaml")
            lines.append(f"tip_element: articol")
            if nr_articol:
                lines.append(f"nr_articol: {nr_articol}")
            if titlu:
                lines.append(f"titlu: {titlu}")
            if capitol:
                lines.append(f"capitol: {capitol}")
            if sectiune:
                lines.append(f"sectiune: {sectiune}")
            lines.append(f"tip_act: {row.get('tip_act', 'N/A')}")
            lines.append(f"nr_act: {row.get('nr_act', 'N/A')}")
            lines.append(f"an_act: {row.get('an_act', 'N/A')}")
            lines.append(f"denumire_act: {row.get('denumire', 'N/A')}")
            lines.append("```")
            lines.append("")
            
            # ConÈ›inut articol
            lines.append("**ConÈ›inut:**")
            lines.append("")
            if text_articol:
                formatted_text = self._format_article_text(text_articol)
                lines.append(formatted_text)
            else:
                lines.append("*[ConÈ›inut lipsÄƒ]*")
            lines.append("")
            lines.append("---")
            lines.append("")
        
        return "\n".join(lines)
    
    def save_to_rezultate(self, df: pd.DataFrame, filename_prefix: str = 'parsed', 
                          metrics: Optional[Dict[str, Any]] = None) -> Dict[str, str]:
        """
        SalveazÄƒ rezultatele Ã®n folderul 'rezultate' Ã®n format CSV È™i Markdown
        
        Args:
            df: DataFrame cu rezultate
            filename_prefix: Prefix pentru numele fiÈ™ierelor (nu se foloseÈ™te)
            metrics: Metrics din parsare (opÈ›ional, pentru validation)
        
        Returns:
            Dict cu cÄƒile fiÈ™ierelor salvate
        """
        # CreeazÄƒ folderul rezultate dacÄƒ nu existÄƒ
        os.makedirs('rezultate', exist_ok=True)
        
        # GenereazÄƒ timestamp pentru nume unice
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        
        # Extrage metadata pentru nume fiÈ™ier: Legea_123_2025_timestamp
        filename = 'act_legislativ'
        if not df.empty and 'tip_act' in df.columns:
            first_row = df.iloc[0]
            tip_act = first_row.get('tip_act', '')
            nr_act = first_row.get('nr_act', '')
            an_act = first_row.get('an_act', '')
            
            if tip_act:
                # NormalizeazÄƒ tipul actului pentru numele fiÈ™ierului
                tip_normalized = tip_act.replace(' ', '_').replace('Ä‚', 'A').replace('Ã‚', 'A').replace('Èš', 'T').replace('È˜', 'S')
                filename_parts = [tip_normalized]
                
                if nr_act:
                    filename_parts.append(str(nr_act))
                
                if an_act:
                    filename_parts.append(str(an_act))
                
                filename = '_'.join(filename_parts)
        
        saved_files = {}
        
        try:
            # SalveazÄƒ CSV
            csv_path = os.path.join('rezultate', f'{filename}_{timestamp}.csv')
            df.to_csv(csv_path, index=False, encoding='utf-8')
            saved_files['csv'] = csv_path
            logger.info(f"âœ… CSV salvat Ã®n: {csv_path}")
            
            # SalveazÄƒ Markdown
            md_path = os.path.join('rezultate', f'{filename}_{timestamp}.md')
            md_content = self._generate_markdown(df)
            with open(md_path, 'w', encoding='utf-8') as f:
                f.write(md_content)
            saved_files['markdown'] = md_path
            logger.info(f"âœ… Markdown salvat Ã®n: {md_path}")
            
        except Exception as e:
            logger.error(f"âŒ Eroare la salvare: {e}")
        
        return saved_files

# FuncÈ›ie de convenienÈ›Äƒ
def parse_legislative_content(content: str, content_type: str = 'auto', 
                            config: Optional[Dict[str, Any]] = None) -> Tuple[pd.DataFrame, Dict[str, Any]]:
    """FuncÈ›ie de convenienÈ›Äƒ pentru parsarea conÈ›inutului legislativ"""
    parser = HybridLegislativeParser(config)
    return parser.parse(content, content_type)

if __name__ == "__main__":
    print("ğŸ§ª Testez parserul simplificat...")
    
    # Test cu fiÈ™ier real dacÄƒ existÄƒ
    if os.path.exists("LEGE 121 30_04_2024.html"):
        with open("LEGE 121 30_04_2024.html", 'r', encoding='utf-8') as f:
            content = f.read()
        
        parser = HybridLegislativeParser()
        df, metrics = parser.parse(content, 'html')
        
        print(f"âœ… Rezultate: {len(df)} articole")
        print(f"âœ… Confidence: {metrics['confidence']:.2f}")
        print(f"âœ… Coloane: {list(df.columns)}")
    else:
        print("âš ï¸ FiÈ™ierul de test nu a fost gÄƒsit")
